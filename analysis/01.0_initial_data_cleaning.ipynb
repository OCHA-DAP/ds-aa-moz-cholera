{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c41623",
   "metadata": {},
   "source": [
    "# Mozambique AA for Cholera – Threshold Analysis\n",
    "\n",
    "This notebook supports the development of Anticipatory Action (AA) for cholera in Mozambique. It focuses on exploring and validating outbreak thresholds as defined in the national cholera preparedness and response plan.\n",
    "\n",
    "The analysis leverages historical cholera case data and related risk indicators stored securely in Azure Blob Storage. Due to the sensitivity of the data, the data is not publicly available.\n",
    "\n",
    "**Objectives:**\n",
    "- Understand the thresholds set by the national plan and assess their applicability.\n",
    "- Explore alternative data-driven thresholds to inform early action.\n",
    "\n",
    "> **Note:** Ensure that access credentials for the Blob Storage container are configured before running the data loading section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9661799",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e19a8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Azure Blob Storage\n",
    "from azure.storage.blob import ContainerClient, BlobClient\n",
    "import io\n",
    "\n",
    "# Display settings\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.options.display.float_format = \"{:,.0f}\".format\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a0226",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_BLOB_SAS = os.getenv(\"DSCI_AZ_BLOB_DEV_SAS\")\n",
    "DEV_BLOB_NAME = \"imb0chd0dev\"\n",
    "DEV_BLOB_URL = f\"https://{DEV_BLOB_NAME}.blob.core.windows.net/\"\n",
    "CONTAINER_NAME = \"projects\"\n",
    "BLOB_PATH = \"ds-aa-moz-cholera/raw/\"\n",
    "BLOB_PATH_WRITE = \"ds-aa-moz-cholera/processed/\"\n",
    "container_url = f\"{DEV_BLOB_URL}{CONTAINER_NAME}?{DEV_BLOB_SAS}\"\n",
    "container_client = ContainerClient.from_container_url(container_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd06e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_blobs = [\n",
    "    blob.name\n",
    "    for blob in container_client.list_blobs(name_starts_with=BLOB_PATH)\n",
    "    if blob.name.endswith((\".xls\", \".xlsx\"))\n",
    "]\n",
    "dataframes = {}\n",
    "for blob_name in excel_blobs:\n",
    "    blob_url = f\"{DEV_BLOB_URL}{CONTAINER_NAME}/{blob_name}?{DEV_BLOB_SAS}\"\n",
    "    blob_client = BlobClient.from_blob_url(blob_url)\n",
    "    blob_data = blob_client.download_blob().readall()\n",
    "    ext = os.path.splitext(blob_name)[1].lower()\n",
    "\n",
    "    if ext in [\".xls\", \".xlsx\"]:\n",
    "        xls = pd.ExcelFile(io.BytesIO(blob_data))\n",
    "        key = os.path.basename(blob_name).replace(ext, \"\")\n",
    "        dataframes[key] = xls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff6e37",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac6e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = []\n",
    "\n",
    "for file_key, xls_file in dataframes.items():\n",
    "    if \"zambezia\" in file_key.lower():\n",
    "        for sheet in xls_file.sheet_names:\n",
    "            sheet_df = xls_file.parse(sheet, header=None)\n",
    "            weeks = sheet_df.iloc[1, 1:53].values  # Row 2, columns B to BA\n",
    "\n",
    "            for row in range(2, 7):  # Rows 3 to 7 (years)\n",
    "                year = sheet_df.iloc[row, 0]\n",
    "                values = sheet_df.iloc[row, 1:53].values\n",
    "\n",
    "                for week, value in zip(weeks, values):\n",
    "                    # Clean week value\n",
    "                    if isinstance(week, str):\n",
    "                        week = week.strip()\n",
    "                        if week.isdigit():\n",
    "                            week_clean = int(week)\n",
    "                        elif week.lower().startswith((\"w\", \"s\")):\n",
    "                            digits = re.sub(r\"\\D\", \"\", week)\n",
    "                            week_clean = int(digits) if digits else None\n",
    "                        else:\n",
    "                            week_clean = None\n",
    "                    elif pd.notna(week):\n",
    "                        week_clean = int(week)\n",
    "                    else:\n",
    "                        week_clean = None\n",
    "\n",
    "                    cleaned_data.append(\n",
    "                        {\n",
    "                            \"province\": \"Zambezia\",\n",
    "                            \"district\": sheet.strip(),\n",
    "                            \"year\": int(year),\n",
    "                            \"week\": week_clean,\n",
    "                            \"cases\": value,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    elif \"nampula\" in file_key.lower():\n",
    "        for sheet in xls_file.sheet_names:\n",
    "            sheet_df = xls_file.parse(sheet, header=None)\n",
    "\n",
    "            # Dynamically find the row with year headers (e.g., B1–H1 or B2–H2)\n",
    "            year_row_idx = next(\n",
    "                (i for i in range(0, 5) if sheet_df.iloc[i, 1:8].notna().all()),\n",
    "                1,  # fallback\n",
    "            )\n",
    "            years = sheet_df.iloc[year_row_idx, 1:8].values\n",
    "\n",
    "            # Find where weeks start by checking column A\n",
    "            week_start_row = next(\n",
    "                (\n",
    "                    i\n",
    "                    for i in range(year_row_idx + 1, sheet_df.shape[0])\n",
    "                    if isinstance(sheet_df.iloc[i, 0], str)\n",
    "                    or pd.notna(sheet_df.iloc[i, 0])\n",
    "                ),\n",
    "                year_row_idx + 1,\n",
    "            )\n",
    "\n",
    "            for col_idx, year in enumerate(years, start=1):\n",
    "                for row in range(week_start_row, sheet_df.shape[0]):\n",
    "                    week = sheet_df.iloc[row, 0]\n",
    "                    value = sheet_df.iloc[row, col_idx]\n",
    "\n",
    "                    # Clean week\n",
    "                    if isinstance(week, str):\n",
    "                        week = week.strip()\n",
    "                        if week.isdigit():\n",
    "                            week_clean = int(week)\n",
    "                        elif week.lower().startswith((\"w\", \"s\")):\n",
    "                            digits = re.sub(r\"\\D\", \"\", week)\n",
    "                            week_clean = int(digits) if digits else None\n",
    "                        else:\n",
    "                            week_clean = None\n",
    "                    elif pd.notna(week):\n",
    "                        week_clean = int(week)\n",
    "                    else:\n",
    "                        week_clean = None\n",
    "\n",
    "                    cleaned_data.append(\n",
    "                        {\n",
    "                            \"province\": \"Nampula\",\n",
    "                            \"district\": sheet.strip(),\n",
    "                            \"year\": int(year),\n",
    "                            \"week\": week_clean,\n",
    "                            \"cases\": value,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "# Combine into DataFrame\n",
    "cholera_df = pd.DataFrame(cleaned_data)\n",
    "cholera_df = cholera_df.sort_values([\"province\", \"district\", \"year\", \"week\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73a7f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_df.to_csv(\n",
    "    Path(os.getenv(\"AA_DATA_DIR\"))\n",
    "    / \"private\"\n",
    "    / \"processed\"\n",
    "    / \"moz\"\n",
    "    / \"cholera\"\n",
    "    / \"cholera_data_cleaned.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_buffer = io.StringIO()\n",
    "# cholera_df.to_csv(csv_buffer, index=False)\n",
    "# csv_bytes = csv_buffer.getvalue().encode(\"utf-8\")\n",
    "\n",
    "# file_name = \"cholera_data_cleaned.csv\"\n",
    "# blob_write_url = (\n",
    "#    DEV_BLOB_URL\n",
    "#    + CONTAINER_NAME\n",
    "#    + \"/\"\n",
    "#    + BLOB_PATH_WRITE\n",
    "#    + file_name\n",
    "#    + \"?\"\n",
    "#    + DEV_BLOB_SAS\n",
    "# )\n",
    "# blob_client = BlobClient.from_blob_url(blob_url)\n",
    "# blob_client.upload_blob(csv_bytes, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
